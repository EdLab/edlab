<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />

    <title>Predicting student engagement and frustration by facial expression recognition tool | EdLab Blog</title>

    <!-- Bootstrap core CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
      integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"
      crossorigin="anonymous"
    />
    <!-- Custom styles for this template -->
    <link href="../css/styles.css" rel="stylesheet" />
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="/">EdLab Archive</a>
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarResponsive"
          aria-controls="navbarResponsive"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="../blogs">Blogs</a>
            </li>
            <li class="nav-item">
              <a class="nav-link " href="../profiles">Profiles</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../events">Events</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../projects">Projects</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container content">
      <div class="row">
        <!-- Post Content Column -->
        <div class="col-lg-8">
          <div class="back-link">
            <a href="./"> &lt; back to list</a>
          </div>
          <!-- Title -->
          <h1 class="mt-4">Predicting student engagement and frustration by facial expression recognition tool</h1>
          <p class="lead">
            Karen Bryner
          </p>
          <hr />

          <!-- Date/Time -->
          <p>
            July 29, 2013
          </p>

          <hr />

          <!-- Post Content -->

          <p>
            <img class='nlt-image' src="https://cdn.tc-library.org/NewLearningTimes/facialexpression_a6e346d8fb484202a186f5d5263e9aa9.png" alt='article.title'><br />

<p><b>Title:</b> Automatically Recognizing Facial Expression: Predicting Engagement and Frustration </p>
<p><b>Authors:</b> Joseph F. Grafsgaard, Joseph B. Wiggins, Kristy Elizabeth Boyer, Eric N. Wiebe, James C. Lester </p>
<p><b>Source:</b> <a href="http://www.educationaldatamining.org/EDM2013/papers/rn_paper_09.pdf" </a>In proceedings of the 6th International Conference on Educational Data Mining</p>
<p><b>Research Question:</b> Can facial expression predict students’ learning? <p>

<p><b>Study Design:</b>
To understand the emotional or affective states of those with whom we interact, we have been taking non-verbal cues from each others’ facial expressions for millennia. In an educational setting, accurately understanding the affective state of students provides opportunities to modify instruction and address the students’ learning needs. In this study, researchers overlaid students’ recorded facial movements with students’ reported cognitive and affective states during online tutoring sessions. University students (N=67) and tutors interacted during tutoring sessions via a chat function on a web-based interface. To assess tutoring session outcomes, students completed identical content-based pre-tests and post-tests. Students also completed a post-session survey designed to measure aspects of their experiences, or affective states, during their sessions. Students reported on, for example, the success of their performance, sense of accomplishment, and levels of frustration. </p>
<p>The <a href="http://mplab.ucsd.edu/~marni/Projects/CERT.htm"> Computer Expression Recognition Toolbox (CERT)</a> was used to track students’ facial movements in video recorded during tutoring sessions. The five most frequently detected facial movements—inner brow raising, outer brow raising, brow lowering, eyelid tightening, and mouth dimpling—were analyzed in this study. Sets of students’ facial expressions were then used to predict learning gains from tutoring sessions. Unlike other facial recognition studies, these researchers also considered intensity and duration of facial movements in their analysis. Although challenges in assessing facial movement, such as students touching or partially covering their faces with their hands, remain, the development of CERT creates a more accurate tool for facial expression recognition. </p>
<p><b>Findings:</b>
The authors discovered that specific facial movements involving eyebrows and mouths predict tutoring outcomes of engagement, frustration, and learning.  Brow lowering was associated with negative outcomes such as frustration and reduced desire to attend additional tutoring sessions. Inner brow raising was positively associated with students finding tutoring sessions worthwhile. Lower frequency of outer brow raising was associated with a lesser sense of being rushed while higher frequencies of outer brow raising predicted reduced learning gains. The frequency of mouth dimpling predicted increased student self-reports of task success and increased learning gains. Eyelid tightening was not included in any predictive models. Additionally, The Computer Expression Recognition Toolbox (CERT) was validated through comparing its output values with manual annotations according to the widely used <a href="http://en.wikipedia.org/wiki/Facial_Action_Coding_System"> Facial Action Coding System</a>.</p>
<p><b>Moving Forward:</b>
Facial expression recognition tools are not new. Although this study did not drill down to students’ moment-to-moment affective states during learning, the results and fine-grained facial expression recognition technology confirm the approach is useful for predicting students’ learning. Such an approach could inform online learning programs of users’ levels and types of engagement and automatically adjust instruction accordingly. Additionally, further development of this technology could lead to automated detection of student engagement during online courses. </p>
<i>Image: </i> Elvert Barnes (via <a href="http://www.flickr.com/photos/95413346@N00/149306757/in/photolist-eceGr-4dG2Yz-8qZDrT-3yBJnK-5scMS-4dL3rC-dU9XbG-5Zxv-4tL12A-edP6e-4gpdVK-edLMh-eciXx-44ATiN-6qE4Rp-8wJcSw-8wFaa8-8wJenq-Bc7X-7BLhFN-4Raqz1-5ziH5g-5znZ1s-65Fp6M-2ntfzw-8BKdn-7kymQU-jKyGd-5bumim-qEgkw-foimi-5MA7U9-QVyM5-edLMj-MLrtH-dMeqgG-7JT4T2-JL4RG-74SyEW-5LPSBP-7Kr3VD-8ZKwVh-4kcYD3-GRdra-6T9vJ1-KGSfs-CQNXc-6Hir3z-3dhdwr-3dmBqN-3dhdcr">Flickr</a>).
          </p>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">
          Copyright &copy; EdLab 2019 <script>new Date().getFullYear()>2019&&document.write("-"+new Date().getFullYear());</script>
        </p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script
      src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
      integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
      integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
