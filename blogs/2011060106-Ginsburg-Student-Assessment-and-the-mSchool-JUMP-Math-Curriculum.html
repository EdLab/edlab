<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />

    <title>Ginsburg, Student Assessment, and the mSchool JUMP Math Curriculum. | EdLab Blog</title>

    <!-- Bootstrap core CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
      integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"
      crossorigin="anonymous"
    />
    <!-- Custom styles for this template -->
    <link href="../css/styles.css" rel="stylesheet" />
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="/">EdLab Archive</a>
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarResponsive"
          aria-controls="navbarResponsive"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="../blogs">Blogs</a>
            </li>
            <li class="nav-item">
              <a class="nav-link " href="../profiles">Profiles</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../events">Events</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../projects">Projects</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container content">
      <div class="row">
        <!-- Post Content Column -->
        <div class="col-lg-8">
          <div class="back-link">
            <a href="./"> &lt; back to list</a>
          </div>
          <!-- Title -->
          <h1 class="mt-4">Ginsburg, Student Assessment, and the mSchool JUMP Math Curriculum.</h1>
          <p class="lead">
            Stephen Pratt
          </p>
          <hr />

          <!-- Date/Time -->
          <p>
            June 1, 2011
          </p>

          <hr />

          <!-- Post Content -->

          <p>
            A publication by Teachers College's own professor Herbert P. Ginsburg holds significant relevance to our currently developing mSchool JUMP curriculum endeavor. The book is entitled “Entering the child's mind: the clinical interview in psychological research”. I've just begun investigating it, but I feel as if it makes a compelling argument for how we should handle assessment practices in any mSchool-based curriculum. 

For those of you who haven't, I highly recommend checking out Skanda's recent blog post on our <a href="http://edlab.tc.columbia.edu/index.php?q=node/5699">mSchool JUMP math curriculum project</a>. The project is still in a very early stage of research, but we'd really appreciate any kind of feedback on the work we've done so far.

Often, automated approaches to learning adopt a particularly uninspired form of student assessment. Exams are basic, fact-focused, and allow almost no room for student error. They are made this way not because of horrendous design but because of computational limitations. Automatically evaluating student responses can get tricky if they are not guaranteed to follow certain standards of input. Non-numerical responses are often restricted to multiple-choice type questions, and the system is typically unable to distinguish between informed mistakes and completely nonsensical errors. Simply put, assessment is usually based of extraordinarily restrictive standardized tests. This is where Ginsburg would take issue.

Ginsburg attacks the prevalence of standardized testing as a form of academic assessment. I'll post a full review of his rationale soon, but for now, I'd like to focus on putting forth the notion of what he refers to as a “clinical interview”.  In Ginsburg's own words, “The phrase clinical interview refers to a class of flexible interview methods which […] typically involve intensive interaction with the individual child, an extended dialog between adult and child, careful observation of the child's work with "concrete" intellectual objects, and flexible questioning tailored to the individual child's distinctive characteristics.”

By nature, of course, a true clinical interview is not something that can be automated. However, it's certainly possible to design software that mimics some of the more beneficial aspects of the clinical interview. For instance, one of the clinical interview's primary advantages is that an it helps instructors to understand student mistakes, and therefore pinpoint areas of misunderstanding. To do this, instructors look at a) student response to a question and b) the student's profile and history of misunderstandings to deduce a possible cause for the gap in knowledge. For instance, if a student summed a two and three digit number to produce a new three digit number of much higher quantity than the original, then the instructor could infer that the student's understanding of place value is incomplete. From here, the instructor can offer feedback that corrects the misunderstanding.

I feel as if the takeaway is this: the assessment system for our new math curriculum and indeed any automated teaching software should be as dynamic as possible. Blindly running down the obvious road and currently accepted pattern of “Lesson->Test” will ultimately accomplish little. If we want our software to properly serve as a teacher, we must design it to work like a teacher. Assessments cannot simply be a function that maps answers to grades. Rather, they must be interactive, adaptive, and dispersed throughout the lesson process.

As I study Ginsburg's work further, I'll grab concrete examples of what he argues the failures of standardized testing and propose ways we can combat them by building a sufficiently dynamic assessment system. I'll also be looking more into the theory of clinical interviews to see how we might be able to emulate them. Perhaps, though, emulation won't even serve as a full substitute. Maybe a one-on-one conferencing a la Proctor U could serve as an integral part of the assessment process.

          </p>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">
          Copyright &copy; EdLab 2019 <script>new Date().getFullYear()>2019&&document.write("-"+new Date().getFullYear());</script>
        </p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script
      src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
      integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
      integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
